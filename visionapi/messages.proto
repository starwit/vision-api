syntax = "proto3";

package visionapi;

option java_package = "de.starwit.visionapi";

message SaeMessage {
  VideoFrame frame = 1;
  repeated Detection detections = 2;
  Metrics metrics = 99;
}

message VideoFrame {
  string source_id = 1;
  uint64 timestamp_utc_ms = 2;
  Shape shape = 3;
  bytes frame_data = 4;
  bytes frame_data_jpeg = 5;
}

message Shape {
  uint32 height = 1;
  uint32 width = 2;
  uint32 channels = 3;
}

message Detection {
  BoundingBox bounding_box = 1;
  float confidence = 2;
  uint32 class_id = 3;
  bytes object_id = 4;
  GeoCoordinate geo_coordinate = 5;
  Point detection_center = 6; 
}

message BoundingBox {
  float min_x = 1;
  float min_y = 2;
  float max_x = 3;
  float max_y = 4;
}

message GeoCoordinate {
  double latitude = 1;
  double longitude = 2;
}

message Point {
  float x = 1;
  float y = 2;
}

//how to realize different approaches?
message AnomalyMessage {
  repeated AnomalyFrame anomalyframes = 1;
  //wollen wir das nochmal speichern?
  uint64 timestamp_utc_ms = 2;
  ModelInfo model_info = 3;
  //in and out message?
  string video_url = 4;
}

//trajectory angle
//scaling factor?
//name???
//eine Anomalie, mehrere Objekte?
message AnomalyFrame {
  uint64 timestamp_utc_ms = 1;
  bytes frame_data_jpeg = 2;
  repeated Detection detections = 3;
}

message ModelInfo {
  string name = 1;
  string version = 2;
}

message Metrics {
  uint32 detection_inference_time_us = 1;
  uint32 tracking_inference_time_us = 2;
}